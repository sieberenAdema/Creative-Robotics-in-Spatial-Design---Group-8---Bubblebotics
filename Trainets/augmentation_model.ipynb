{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc31e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf<5 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.25.8)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.57.0)\n",
      "Requirement already satisfied: torch in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kayla\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kayla\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kayla\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kayla\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kayla\\.cache\\huggingface\\hub\\models--eugenesiow--bart-paraphrase. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Augmenting:   0%|          | 0/211 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Augmenting: 100%|██████████| 211/211 [02:14<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset saved: 211 → 417 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Small paraphrasing model to augment dataset for classification task\n",
    "%pip install \"protobuf<5\" tiktoken transformers torch tqdm sentencepiece\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import json, random\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_NAME = \"eugenesiow/bart-paraphrase\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def paraphrase(text, num_return_sequences=2, num_beams=5):\n",
    "    prompt = f\"paraphrase: {text} </s>\"\n",
    "    encoding = tokenizer.encode_plus(prompt, padding='longest', return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        **encoding,\n",
    "        max_length=64,\n",
    "        num_beams=num_beams,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        temperature=1.5\n",
    "    )\n",
    "    return [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "\n",
    "# Load the dataset I want to augment\n",
    "data = []\n",
    "with open(\"dataset.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "augmented = []\n",
    "\n",
    "for entry in tqdm(data, desc=\"Augmenting\"):\n",
    "    if random.random() < 0.5:  # augment 50% of samples\n",
    "        new_texts = paraphrase(entry[\"text\"], num_return_sequences=2)\n",
    "        for t in new_texts:\n",
    "            augmented.append({\"text\": t, \"label\": entry[\"label\"]})\n",
    "\n",
    "# Save augmented + original in a new file called data_augmented.jsonl\n",
    "all_data = data + augmented\n",
    "with open(\"data_augmented.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for ex in all_data:\n",
    "        json.dump(ex, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Augmented dataset saved: {len(data)} → {len(all_data)} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
